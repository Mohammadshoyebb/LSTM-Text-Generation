{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xzJfFKXtT8O0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = keras.utils.get_file(\"nietzsche.txt\",\n",
        "                            origin = 'http://s3.amazonaws.com/text-datasets/nietzsche.txt')"
      ],
      "metadata": {
        "id": "EkP_V22dUpqm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e62d2516-e62e-473c-819c-2dfd9e08dfeb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
            "600901/600901 [==============================] - 0s 1us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(path).read().lower()"
      ],
      "metadata": {
        "id": "_5w4GPhIVh6o"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Corpus Lenght: \", len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpUb357sVoTs",
        "outputId": "89cfbc25-c6ed-4739-94dd-ee431f790bae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus Lenght:  600893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 60\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0,len(text) - maxlen, step):\n",
        "  sentences.append(text[i: i + maxlen])\n",
        "  next_chars.append(text[i + maxlen])\n",
        "print(\"Number of Sequences:\" , len(sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFT2ppPVVvF7",
        "outputId": "56e7bbdb-8c6d-4c88-e229-fcdd3c68d596"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Sequences: 200278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "print(\"Unique Characters: \", len(chars))\n",
        "\n",
        "char_indices = dict((char, char.index(char))for char in chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yA9h4GteWkNl",
        "outputId": "26953a41-7956-40f1-afc5-c6b7cb3740b0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique Characters:  57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Next, one-hot encode the characters into binary arrays.\n",
        "print('Vectorization ... ')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool_)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool_)\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for t, char in enumerate(sentence):\n",
        "    x[i, t, char_indices[char]] = 1\n",
        "  y[i, char_indices[next_chars[i]]] = _\n",
        "print(' ... done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQeiOtSPXLa4",
        "outputId": "94dc550a-39a3-40e6-9e03-6dc68c3a256c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorization ... \n",
            " ... done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(layers. Dense(len(chars), activation='softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "\n",
        "model. summary ()"
      ],
      "metadata": {
        "id": "82i95N9TZIz3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a816318e-cdeb-45d6-ecf2-45e024f21ba2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 128)               95232     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 57)                7353      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 102585 (400.72 KB)\n",
            "Trainable params: 102585 (400.72 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "  preds = np.asarray(preds). astype('float64')\n",
        "  preds = np.log(preds) / temperature\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds / np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(1, preds, 1)\n",
        "\n",
        "  return np.argmax(probas)"
      ],
      "metadata": {
        "id": "-nJ2sFz5aDgH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import sys\n",
        "\n",
        "NUM_EPOCHS = 3\n",
        "CHAR_GENERATED_TEXT = 400 # We generate 400 characters\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS):\n",
        "  print('epoch', epoch)\n",
        "\n",
        "# Fit the model for 1 epoch on the available training data\n",
        "  model.fit(x, y, batch_size=128, epochs=1)\n",
        "\n",
        "# Select a text seed at random\n",
        "  start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "  generated_text = text[start_index: start_index + maxlen]\n",
        "  print(f\" --- Generating with seed: \\\"{generated_text}\\\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LinmNmubYj3",
        "outputId": "365f7a3c-4247-4e28-a2d6-a70969886246"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1\n",
            "1565/1565 [==============================] - 181s 114ms/step - loss: 0.0000e+00\n",
            " --- Generating with seed: \"ing in body and soul. that, however,\n",
            "which is most diseased \"\n",
            "epoch 2\n",
            "1565/1565 [==============================] - 167s 107ms/step - loss: 0.0000e+00\n",
            " --- Generating with seed: \"lf-observers who believe that there are\n",
            "\"immediate certainti\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
        "  print(f\"-----temperature;{temperature}\")\n",
        "  sys. stdout.write(generated_text)\n",
        "\n",
        "  for i in range(CHAR_GENERATED_TEXT):\n",
        "    sampled = np.zeros((1, maxlen, len(chars)))\n",
        "    for t, char in enumerate(generated_text):\n",
        "      sampled[0, t, char_indices[char]] = 1.\n",
        "    preds = model.predict(sampled, verbose=0)[0]\n",
        "    next_index = sample(preds, temperature)\n",
        "    next_char = chars[next_index]\n",
        "\n",
        "  generated_text += next_char\n",
        "  generated_text = generated_text[1:]\n",
        "\n",
        "  sys.stdout.write(next_char)\n",
        "  sys.stdout.flush()\n",
        "print()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsfON6oncUT3",
        "outputId": "17330ffa-3b5f-47cb-8479-7eeafe6a8cea"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----temperature;0.2\n",
            "lf-observers who believe that there are\n",
            "\"immediate certainti(-----temperature;0.5\n",
            "f-observers who believe that there are\n",
            "\"immediate certainti((-----temperature;1.0\n",
            "-observers who believe that there are\n",
            "\"immediate certainti(((-----temperature;1.2\n",
            "observers who believe that there are\n",
            "\"immediate certainti(((p\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RXkNYnu1e9vi"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}